---
title           : "Advancinging the shift-of-strategy (SoS) approach: Shifting counter-interrogation strategies in extended interrogations"
shorttitle      : "OSF preregistration"
date            : "`r Sys.setlocale('LC_TIME', 'C'); format(Sys.time(), '%d\\\\. %B %Y')`"

author: 
  - name        : Lina Nyström
    affiliation : 1
  - name        : Timothy J Luke
    affiliation : 1
  - name        : Pär Anders Granhag
    affiliation : 1

affiliation:
  - id          : 1
    institution : University of Gothenburg

output: prereg::cos_prereg
---

# Study Information

## Title
<!-- Provide the working title of your study. It may be the same title that you submit for publication of your final manuscript, but it is not a requirement. The title should be a specific and informative description of a project. Vague titles such as 'Fruit fly preregistration plan' are not appropriate.

Example: Effect of sugar on brownie tastiness. -->

`r rmarkdown::metadata$title`


## Description
<!-- Please give a brief description of your study, including some background, the purpose of the of the study, or broad research questions. The description should be no longer than the length of an abstract. It can give some context for the proposed study, but great detail is not needed here for your preregistration.

Example: Though there is strong evidence to suggest that sugar affects taste preferences, the effect has never been demonstrated in brownies. Therefore, we will measure taste preference for four different levels of sugar concentration in a standard brownie recipe to determine if the effect exists in this pastry. -->

Our aim is to assess the SoS-approach (Luke & Granhag, 2020) in longer interviews and to test a new variation of the technique that we call SoS-Reinforcement.

Our main research questions concern the comparison between the two SoS-conditions regarding sources’ disclosure of critical information, as well as assessing if SoS-Standard holds up as more effective than direct questioning in longer interviews. 

We will also assess and compare participants' experiences being interrogated using the different techniques. 


## Hypotheses
<!-- List specific, concise, and testable hypotheses. Please state if the hypotheses are directional or non-directional. If directional, state the direction. A predicted effect is also appropriate here. If a specific interaction or moderation is important to your research, you can list that as a separate hypothesis.

Example: If taste affects preference, then mean preference indices will be higher with higher concentrations of sugar. -->

###Information disclosure

The SoS-Standard technique and the SoS-Reinforcement technique are identical for the first three themes of the interview. Therefore, participants in the SoS-Standard and SoS-Reinforcement conditions should not disclose significantly different amounts of information during the first three themes of the interview. 

We predict that participants in the SoS-Reinforcement condition will disclose more information during the last three themes of the interview (following the Reinforcement stage) in comparison to participants in the SoS-Standard condition. Though we expect to see a decrease in disclosed information for the critical phases of the interview for all conditions, we expect the drop in disclosed information to be less severe in the SoS-Reinforcement condition than in the SoS-Standard condition.

(Exploratory) We want to explore if the Reinforcement stage has an instant effect on participants’ disclosure of crime relevant information. We will test whether participants in the SoS-Reinforcement condition disclose more information immediately after the Reinforcement-stage (theme four) than participants in the SoS-Standard condition.

###Performance

(Exploratory) We will test whether the SoS conditions assess their performance more poorly than the Direct condition.

(Exploratory) We will run an exploratory analysis to assess if all conditions on average assess their performance as better than the midpoint of the scale.

###Interaction quality

We expect that (1) the SoS conditions will not assess the interaction or the interviewer more poorly than the direct questioning condition, and (2) all conditions will on average assess the interaction and the interviewer as more positive than the negative endpoint of the scale.


# Design Plan
<!-- In this section, you will be asked to describe the overall design of your study. Remember that this research plan is designed to register a single study, so if you have multiple experimental designs, please complete a separate preregistration. -->


## Study type

**Experiment**. A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.


## Blinding
<!-- Blinding describes who is aware of the experimental manipulations within a study. Select all that apply. Is there any additional blinding in this study? -->

For studies that involve human subjects, they will not know the treatment group to which they have been assigned.

Experimenters and interviewers will not be aware of the study's hypotheses. 


## Study design
<!-- Describe your study design. Examples include two-group, factorial, randomized block, and repeated measures. Is it a between (unpaired), within-subject (paired), or mixed design? Describe any counterbalancing required. Typical study designs for observation studies include cohort, cross sectional, and case-control studies.

This question has a variety of possible answers. The key is for a researcher to be as detailed as is necessary given the specifics of their design. Be careful to determine if every parameter has been specified in the description of the study design. There may be some overlap between this question and the following questions. That is OK, as long as sufficient detail is given in one of the areas to provide all of the requested information. For example, if the study design describes a complete factorial, 2 X 3 design and the treatments and levels are specified previously, you do not have to repeat that information.

Example: We have a between subjects design with 1 factor (sugar by mass) with 4 levels. -->

We will have a between subjects design with 3 interview conditions; Direct, SoS-Standard and SoS-Reinforcement. 


## Randomization
<!-- If you are doing a randomized study, how will you randomize, and at what level? Typical randomization techniques include: simple, block, stratified, and adaptive covariate randomization. If randomization is required for the study, the method should be specified here, not simply the source of random numbers.

Example: We will use block randomization, where each participant will be randomly assigned to one of the four equally sized, predetermined blocks. The random number list used to create these four blocks will be created using the web applications available at https://random.org. -->

Participants will complete one out of three online mock crime procedures. All three mock crime procedures consists of two blocks (each block contains three mock crime stages). The blocks will be presented to the participants in a balanced order to account for possible order effects. With two blocks, each mock crime could be presented in two different ways, resulting in a total of six different mock crime procedures.  

We have no hypotheses regarding differences between the mock crime procedures. We include three different mock crime procedures in our experiment to reduce the possibility of results stemming from features from any individual mock crime. 

Three different interview conditions and six mock crime procedures means there are 18 different versions of the experiment that a participant could encounter. Participants will be randomized to participate in one of the 18 versions of the experiment. See participant version assignment list and code that generated the list in project file storage. 


# Sampling Plan
<!-- In this section we’ll ask you to describe how you plan to collect samples, as well as the number of samples you plan to collect and your rationale for this decision. Please keep in mind that the data described in this section should be the actual data used for analysis, so if you are using a subset of a larger dataset, please describe the subset that will actually be used in your study. -->


## Existing data
<!-- Preregistration is designed to make clear the distinction between confirmatory tests, specified prior to seeing the data, and exploratory analyses conducted after observing the data. Therefore, creating a research plan in which existing data will be used presents unique challenges. Please select the description that best describes your situation. Please do not hesitate to contact us if you have questions about how to answer this question (prereg@cos.io). -->

**Registration prior to creation of data**. As of the date of submission of this research plan for preregistration, the data have not yet been collected, created, or realized. 


## Data collection procedures
<!-- Please describe the process by which you will collect your data. If you are using human subjects, this should include the population from which you obtain subjects, recruitment efforts, payment for participation, how subjects will be selected for eligibility from the initial pool (e.g. inclusion and exclusion rules), and your study timeline. For studies that donÍt include human subjects, include information about how you will collect samples, duration of data gathering efforts, source or location of samples, or batch numbers you will use.

The answer to this question requires a specific set of instructions so that another person could repeat the data collection procedures and recreate the study population. Alternatively, if the study population would be unable to be reproduced because it relies on a specific set of circumstances unlikely to be recreated (e.g., a community of people from a specific time and location), the criteria and methods for creating the group and the rationale for this unique set of subjects should be clear.

Example: Participants will be recruited through advertisements at local pastry shops. Participants will be paid $10 for agreeing to participate (raised to $30 if our sample size is not reached within 15 days of beginning recruitment). Participants must be at least 18 years old and be able to eat the ingredients of the pastries. -->

Participants will be recruited through Prolific (prolific.co). Participants will be paid  XX GBP for their participation. Participants must be at least 18 years old and reside in the UK to be eligible to participate in the study.

Participants will be recruited to take part in an online mock crime that will involve multiple discrete events and substantial detail. Luke and Granhag (2020) used mock crimes with three stages. Here, to create the circumstances that could lead to especially lengthy interrogations, we will use mock crimes composed of six stages.

Participants will complete an online survey on Qualtrics (qualtrics.com). The participants will be asked to watch two short video clips within the survey, each containing three mock crime stages. The clips act as the two online mock crime blocks. The video clips are filmed in a first person point of view, depicting a gloved person committing various crimes (clips available in file project file storage). The participants will be asked to imagine that they are the person committing the crimes shown in the clips. After watching the clips the participants will be interrogated via video conference on Zoom (zoom.us) about their activities. After completing the interrogation the participants will return to the Qualtrics survey and answer questions about their experience with the interrogation. All interrogations will be recorded for transcription and coding of dependent variables.


## Sample size
<!-- Describe the sample size of your study. How many units will be analyzed in the study? This could be the number of people, birds, classrooms, plots, interactions, or countries included. If the units are not individuals, then describe the size requirements for each unit. If you are using a clustered or multilevel design, how many units are you collecting at each level of the analysis? For some studies, this will simply be the number of samples or the number of clusters. For others, this could be an expected range, minimum, or maximum number.

Example: Our target sample size is 280 participants. We will attempt to recruit up to 320, assuming that not all will complete the total task. -->

Our target sample size is 300 participants. 


## Sample size rationale
<!-- This could include a power analysis or an arbitrary constraint such as time, money, or personnel. This gives you an opportunity to specifically state how the sample size will be determined. A wide range of possible answers is acceptable; remember that transparency is more important than principled justifications. If you state any reason for a sample size upfront, it is better than stating no reason and leaving the reader to "fill in the blanks." Acceptable rationales include: a power analysis, an arbitrary number of subjects, or a number based on time or monetary constraints.

Example: We used the software program G*Power to conduct a power analysis. Our goal was to obtain .95 power to detect a medium effect size of .25 at the standard .05 alpha error probability. -->

The resources available to us permit us to collect 300 responses.

Power calculations indicate that this sample size will permit us to detect effects of d = .40 with .80 power when comparing between each of the three groups in the design.


## Stopping rule
<!-- If your data collection procedures do not give you full control over your exact sample size, specify how you will decide when to terminate your data collection. 

You may specify a stopping rule based on p-values only in the specific case of sequential analyses with pre-specified checkpoints, alphas levels, and stopping rules. Unacceptable rationales include stopping based on p-values if checkpoints and stopping rules are not specified. If you have control over your sample size, then including a stopping rule is not necessary, though it must be clear in this question or a previous question how an exact sample size is attained.

Example: We will post participant sign-up slots by week on the preceding Friday night, with 20 spots posted per week. We will post 20 new slots each week if, on that Friday night, we are below 320 participants. -->

We will post participant sign-up slots continuously until we have collected 300 usable interviews. The amount of available sign-up slots will vary with experimenter and interviewer availability. 


# Variables
<!-- In this section you can describe all variables (both manipulated and measured variables) that will later be used in your confirmatory analysis plan. In your analysis plan, you will have the opportunity to describe how each variable will be used. If you have variables which you are measuring for exploratory analyses, you are not required to list them, though you are permitted to do so. -->


## Manipulated variables
<!-- Describe all variables you plan to manipulate and the levels or treatment arms of each variable. This is not applicable to any observational study. For any experimental manipulation, you should give a precise definition of each manipulated variable. This must include a precise description of the levels at which each variable will be set, or a specific definition for each categorical treatment. For example, “loud or quiet,” should instead give either a precise decibel level or a means of recreating each level. 'Presence/absence' or 'positive/negative' is an acceptable description if the variable is precisely described.

Example: We manipulated the percentage of sugar by mass added to brownies. The four levels of this categorical variable are: 15%, 20%, 25%, or 40% cane sugar by mass. -->

We will use a three-group experimental design, in which participants serving as mock intelligence sources will be questioned with one of three interrogation techniques (i.e., Direct questioning, SoS-Standard, and SoS-Reinforcement).
 
In the Reinforcement condition, the interrogator will pause after covering several topics to summarize the source’s statement and give him or her the opportunity to offer clarifications, corrections, or modifications. During this summary, the interrogator will place special emphasis on the parts of the statement that are consistent or inconsistent with the interrogator’s knowledge, without judgment and without accusing the source of lying. Thus, the source will be given an additional signal that becoming forthcoming and consistent with the evidence may be a productive strategy (and that being withholding and inconsistent is potentially damaging). We will compare this new variation to the version of the approach that Luke and Granhag (2020) found most effective (SoS-Standard) and to a technique in which inconsistencies are not challenged (Direct).

The techniques vary in the manner in which the interviewer responds to statement-evidence inconsistencies. In the Direct condition the interviewer relies on direct questioning and will not challenge the suspects on any statement-evidence inconsistencies. In both the SoS-Standard and SoS-Reinforcement conditions the interviewer challenges inconsistencies without delay. 

Interview scripts and instructions available in project file storage.


## Measured variables
<!-- Describe each variable that you will measure. This will include outcome measures, as well as any predictors or covariates that you will measure. You do not need to include any variables that you plan on collecting if they are not going to be included in the confirmatory analyses of this study.

Observational studies and meta-analyses will include only measured variables. As with the previous questions, the answers here must be precise. For example, 'intelligence,' 'accuracy,' 'aggression,' and 'color' are too vague. Acceptable alternatives could be 'IQ as measured by Wechsler Adult Intelligence Scale' 'percent correct,' 'number of threat displays,' and 'percent reflectance at 400 nm.'

Example: The single outcome variable will be the perceived tastiness of the single brownie each participant will eat. We will measure this by asking participants ‘How much did you enjoy eating the brownie’ (on a scale of 1-7, 1 being 'not at all', 7 being 'a great deal') and 'How good did the brownie taste' (on a scale of 1-7, 1 being 'very bad', 7 being 'very good'). -->

We will measure participants’ disclosure of (truthful) information in each phase of the interrogation (i.e., related to each discrete activity they performed). Measuring disclosure across multiple time points will permit us to assess potentially different “trajectories” an interrogation can take as a function of the different techniques.

For each phase of each mock crime, we have identified five details with increasing specificity and coded whether the participants' statement to the interviewer reveal those truthful details. The revelation of each detail necessarily implied revelation of less specific details (i.e., admitting to the most specific detail entailed admitting to all the less specific details), thus forming a 0 to 5 score for each phase of each mock crime (See coding scheme in file storage). 

We will assess participants’ perception of how successful they were at convincing the interviewer they were innocent using self-reported endorsement of four statements about their performance in the interview. We will also assess participants’ perceptions of the quality of the interaction and the interviewer using their self-reported endorsement of lists of positive and negative adjectives (6 for the interaction, i.e., smooth, awkward, comfortable, difficult, open, and pleasant; and 6 for the interviewer, i.e., friendly, pressing, aggressive, sympathetic, interested, and harsh).


## Indices
<!-- If any measurements are  going to be combined into an index (or even a mean), what measures will you use and how will they be combined? Include either a formula or a precise description of your method. If your are using a more complicated statistical method to combine measures (e.g. a factor analysis), you can note that here but describe the exact method in the analysis plan section.

If you are using multiple pieces of data to construct a single variable, how will this occur? Both the data that are included and the formula or weights for each measure must be specified. Standard summary statistics, such as "means" do not require a formula, though more complicated indices require either the exact formula or, if it is an established index in the field, the index must be unambiguously defined. For example, "biodiversity index" is too broad, whereas "Shannon’s biodiversity index" is appropriate.

Example: We will take the mean of the two questions above to create a single measure of 'brownie enjoyment.'  -->

We will create three composite measures. One for the items regarding participants' self-assessment of performance, one for interaction quality and lastly one for interviewer quality (some items reverse coded so that higher values indicate more positive assessments)(see analysis code, available in project file storage). All three composites will be created by calculating the mean of the respective combined items.


# Analysis Plan
<!-- You may describe one or more confirmatory analysis in this preregistration. Please remember that all analyses specified below must be reported in the final article, and any additional analyses must be noted as exploratory or hypothesis generating.

A confirmatory analysis plan must state up front which variables are predictors (independent) and which are the outcomes (dependent), otherwise it is an exploratory analysis. You are allowed to describe any exploratory work here, but a clear confirmatory analysis is required. -->


## Statistical models
<!-- What statistical model will you use to test each hypothesis? Please include the type of model (e.g. ANOVA, multiple regression, SEM, etc) and the specification of the model (this includes each variable that will be included as predictors, outcomes, or covariates). Please specify any interactions, subgroup analyses, pairwise or complex contrasts, or follow-up tests from omnibus tests. If you plan on using any positive controls, negative controls, or manipulation checks you may mention that here. Remember that any test not included here must be noted as an exploratory test in your final article.

This is perhaps the most important and most complicated question within the preregistration. As with all of the other questions, the key is to provide a specific recipe for analyzing the collected data. Ask yourself: is enough detail provided to run the same analysis again with the information provided by the user? Be aware for instances where the statistical models appear specific, but actually leave openings for the precise test. See the following examples:

- If someone specifies a 2x3 ANOVA with both factors within subjects, there is still flexibility with the various types of ANOVAs that could be run. Either a repeated measures ANOVA (RMANOVA) or a multivariate ANOVA (MANOVA) could be used for that design, which are two different tests. 
- If you are going to perform a sequential analysis and check after 50, 100, and 150 samples, you must also specify the p-values you’ll test against at those three points.

Example:  We will use a one-way between subjects ANOVA to analyze our results. The manipulated, categorical independent variable is 'sugar' whereas the dependent variable is our taste index. -->

###Disclosure of information

We will assess our predictions by fitting a linear mixed effects model with fixed effects for time, time after treatment and immediate treatment, interview condition (treatment contrasts with SoS-Standard as reference group), and their interaction term, as well as random effects (intercepts) for each participant(nested in mock crime orders),crime event (nested in mock crime orders) and interviewer.

###Self-assesment of performance

As a check on the effectiveness of creating an environment that did not stifle sources’ motivation, we will compare sources’ self-assessed performance between each of the three conditions using t-tests (Welch corrected). If these comparisons are nonsignificant, we will conduct follow-up equivalence tests, with a TOST approach (equivalence bounds set at |.20|). We will also test whether the mean self-assessment in each condition is significantly greater than the midpoint of the scale (3).

###Interaction quality

We will compare sources’ interaction and interviewer ratings between each of the three conditions using t-tests (Welch corrected). If these comparisons are nonsignificant, we will conduct follow-up equivalence tests, with a TOST approach (equivalence bounds set at |.20|). We will also test whether the mean ratings in each condition are significantly greater than the negative endpoint of the scale (1). We are comparing ratings to the endpoint of the scale because we do not necessarily expect the interactions to be perceived as positive overall (given their adversarial nature), but we view this as a test of whether people perceive the interaction as not having been highly aversive overall. If the SoS conditions in particular are perceived highly negatively, it may indicate practical or ethical issues with the approach.


## Transformations
<!-- If you plan on transforming, centering, recoding the data, or will require a coding scheme for categorical variables, please describe that process. If any categorical predictors are included in a regression, indicate how those variables will be coded (e.g. dummy coding, summation coding, etc.) and what the reference category will be.

Example: The "Effect of sugar on brownie tastiness" does not require any additional transformations. However, if it were using a regression analysis and each level of sweet had been categorically described (e.g. not sweet, somewhat sweet, sweet, and very sweet), 'sweet' could be dummy coded with 'not sweet' as the reference category. -->

We will reverse code interaction quality items "awkward", and "difficult". We will also reverse code interviewer quality items "pressing", "aggressive" and "harsh". 

## Inference criteria
<!-- What criteria will you use to make inferences? Please describe the information youÍll use (e.g. p-values, bayes factors, specific model fit indices), as well as cut-off criterion, where appropriate. Will you be using one or two tailed tests for each of your analyses? If you are comparing multiple conditions or testing multiple hypotheses, will you account for this?

p-values, confidence intervals, and effect sizes are standard means for making an inference, and any level is acceptable, though some criteria must be specified in this or previous fields. Bayesian analyses should specify a Bayes factor or a credible interval. If you are selecting models, then how will you determine the relative quality of each? In regards to multiple comparisons, this is a question with few "wrong" answers. In other words, transparency is more important than any specific method of controlling the false discovery rate or false error rate. One may state an intention to report all tests conducted or one may conduct a specific correction procedure; either strategy is acceptable.

Example: We will use the standard p<.05 criteria for determining if the ANOVA and the post hoc test suggest that the results are significantly different from those expected if the null hypothesis were correct. The post-hoc Tukey-Kramer test adjusts for multiple comparisons. -->

We will use α = 0.05 when assessing our analyses. 


## Data exclusion
<!-- How will you determine what data or samples, if any, to exclude from your analyses? How will outliers be handled? Will you use any awareness check? Any rule for excluding a particular set of data is acceptable. One may describe rules for excluding a participant or for identifying outlier data.

Example: No checks will be performed to determine eligibility for inclusion besides verification that each subject answered each of the three tastiness indices. Outliers will be included in the analysis. -->

Participants who fail to adhere to instructions regarding the interview (e.g. does not attempt to convince the interviewer that they are innocent or otherwise deviates from the procedure substantially) will be excluded from analysis.

Data will be excluded if two people on the research team agree that it should be excluded without having looked at the data. 


## Missing data
<!-- How will you deal with incomplete or missing data? Any relevant explanation is acceptable. As a final reminder, remember that the final analysis must follow the specified plan, and deviations must be either strongly justified or included as a separate, exploratory analysis.

Example: If a subject does not complete any of the three indices of tastiness, that subject will not be included in the analysis. -->

Subjects who do not complete the full interview will be not be included in the analysis. 


## Exploratory analyses (optional)
<!-- If you plan to explore your data set to look for unexpected differences or relationships, you may describe those tests here. An exploratory test is any test where a prediction is not made up front, or there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could be registered at a later time.

Example: We expect that certain demographic traits may be related to taste preferences. Therefore, we will look for relationships between demographic variables (age, gender, income, and marital status) and the primary outcome measures of taste preferences. -->

Enter your response here.


# Other

## Other (Optional)
<!-- If there is any additional information that you feel needs to be included in your preregistration, please enter it here. Literature cited, disclosures of any related work such as replications or work that uses the same data, or other context that will be helpful for future readers would be appropriate here. -->

Enter your response here.


# References
## 
\vspace{-2pc}
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{-1in}
\setlength{\parskip}{8pt}
\noindent

